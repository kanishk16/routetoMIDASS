{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python_Problem.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanishk16/routetoMIDASS/blob/master/Python_Problem/Python_Problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "feTUySxqcVmw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">**Necessary Installations & Imports**"
      ]
    },
    {
      "metadata": {
        "id": "S8n8DD1kvsAl",
        "colab_type": "code",
        "outputId": "cc061513-b9e3-41da-805d-899c7aa97aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install jsonlines"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.11.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JsgcVXdHuK39",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import jsonlines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jlpZdnmS5Nkw",
        "colab_type": "code",
        "outputId": "9660d2e8-3acc-4d14-d12e-980b09b30ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!wget -c https://github.com/wbolster/jsonlines/tree/1.2.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-06 18:58:10--  https://github.com/wbolster/jsonlines/tree/1.2.0\n",
            "Resolving github.com (github.com)... 192.30.255.112, 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘1.2.0’\n",
            "\n",
            "\r1.2.0                   [<=>                 ]       0  --.-KB/s               \r1.2.0                   [ <=>                ]  82.30K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-04-06 18:58:10 (5.48 MB/s) - ‘1.2.0’ saved [84279]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C4zgnHyLc2kU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> **Task 1a : A python script to fetch all the tweets(as many as allowed by Twitter API) done by @midasIIITD twitter handle and dump the responses into JSONlines file**"
      ]
    },
    {
      "metadata": {
        "id": "yMZAAqsVdUPP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> **Authorization for Twitter API**"
      ]
    },
    {
      "metadata": {
        "id": "2c8KVhnFko67",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Stores tokens and keys\n",
        "\"\"\"\n",
        "consumer_key = \"f69Ch2S4kVRsXbaZwhs0Qhc7M\"\n",
        "consumer_secret = \"Z43Y85EwvKe3tOHVNAfvxEx7r7jmNliHhXDgZsdSnXuRIZKLKz\"\n",
        "access_key = \"1034447027923374082-ftqEyERgMoJ8s8sMFICXfxy7UC44vs\"\n",
        "access_secret = \"p8hg6CRuXVzn9yFxrnwObSCrm0gmW2PhKiveqw9SLwzsg\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XsXe9I41d_lt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> **Function to fetch all tweets**"
      ]
    },
    {
      "metadata": {
        "id": "HubLxZVqlBJs",
        "colab_type": "code",
        "outputId": "642fbb90-72bc-4b05-818a-4e67397ec31d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "# Function to extract tweets \n",
        "def get_tweets(username): \n",
        "          \n",
        "        # Authorization to consumer key and consumer secret \n",
        "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
        "  \n",
        "        # Access to user's access key and access secret \n",
        "        auth.set_access_token(access_key, access_secret) \n",
        "  \n",
        "        # Calling api \n",
        "        api = tweepy.API(auth) \n",
        "  \n",
        "        # tweets to be extracted \n",
        "        number_of_tweets=5\n",
        "        tweets = api.user_timeline(screen_name=username) \n",
        "  \n",
        "        # Empty Array \n",
        "        tmp=[]  \n",
        "        \n",
        "        images = 0\n",
        "        for tweet in tweets:\n",
        "          tweet_media = str(tweet.entities) \n",
        "          images = tweet_media.count(\"photo\")\n",
        "          #if \"photo\" in tweet_media:\n",
        "          #  images += 1 \n",
        "          print(images)\n",
        "  \n",
        "        # create array of tweet information: text, date/time, favorites/likes, retweets, media \n",
        "        tweets_for_csv = [[tweet.text, str(tweet.created_at), tweet.favorite_count, tweet.retweet_count, images] for tweet in tweets] \n",
        "        for j in tweets_for_csv: \n",
        "            \n",
        "            #print(type(tweets_for_csv))\n",
        "            # Appending tweets to the empty array tmp \n",
        "            tmp.append(j)  \n",
        "           \n",
        "        # Open a JSON file to dump all the tweets\n",
        "        with jsonlines.open('/content/twitter1.jsonl', mode='w') as writer:\n",
        "          writer.write_all(tmp)\n",
        "        \n",
        "        # Printing the tweets \n",
        "        print(\"RECORDED\") \n",
        "  \n",
        "  \n",
        "if __name__ == '__main__': \n",
        "  \n",
        "    # Twitter handle whose tweets are to be extracted \n",
        "    get_tweets(\"midasIIITD\") "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "RECORDED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7igwJn1TXnqm",
        "colab_type": "code",
        "outputId": "c25d5051-4a25-40a4-9da3-7961ee6ea974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.6)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kJMtrN75HigV",
        "colab_type": "code",
        "outputId": "025b6eae-c7e7-45b5-c796-106479536c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1108
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "with jsonlines.open('/content/twitter1.jsonl', mode='r') as reader:\n",
        "  #print(reader.read())\n",
        "  #print(type(reader))\n",
        "  labels = ['text','time','likes','retweets', 'images']\n",
        "  df = pd.DataFrame(columns =labels)\n",
        "  for r in reader:\n",
        "    print(r)\n",
        "    #df1 = df.append(pd.Series([r], index = labels), ignore_index=True)\n",
        "    #print(df1)\n",
        "    df = pd.DataFrame([r], columns = labels).append(df, ignore_index=True)\n",
        "    #df1= df.append(pd.Series([r], index=labels)\n",
        "    #print(df1.tolist(), columns =labels)\n",
        "print(df)  "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['RT @IIITDelhi: We are delighted to share that IIIT-Delhi is ranked 55 by NIRF this year. We have moved up by 11 positions compared to the p…', '2019-04-09 16:45:07', 0, 9, 0]\n",
            "['RT @Harvard: Professor Jelani Nelson founded AddisCoder, a program that teaches students in Ethiopia how to code https://t.co/0sM06p4qxw', '2019-04-09 05:04:27', 0, 35, 0]\n",
            "['RT @emnlp2019: For anyone interested in submitting to EMNLP 2019, the anonymity period begins in less two weeks, on April 21.\\nhttps://t.co/…', '2019-04-09 05:04:11', 0, 12, 0]\n",
            "['RT @multimediaeval: Announcing the 2019 MediaEval multimedia tasks: https://t.co/V6NMt1vaNV Participation is open for anyone who is interes…', '2019-04-08 19:38:09', 0, 15, 0]\n",
            "['Many Congratulations to @midasIIITD student, Shagun Uppal @shagunuppls, on getting selected for the summer internsh… https://t.co/bzhiSm4zuB', '2019-04-08 07:08:12', 14, 2, 0]\n",
            "['@midasIIITD thanks all students who have appeared for the interview yesterday. We will announce the interview resul… https://t.co/qxESgZPtKJ', '2019-04-08 03:27:42', 5, 0, 0]\n",
            "['@himanchalchandr Meanwhile, complete CV/NLP task first.', '2019-04-07 14:17:29', 0, 0, 0]\n",
            "['@sayangdipto123 Submit as per the guideline again.', '2019-04-07 14:17:09', 0, 0, 0]\n",
            "['We request all students whose interview are scheduled today to join at the time given to them and not before or aft… https://t.co/7cnrlj1b9Q', '2019-04-07 11:43:24', 1, 1, 0]\n",
            "['Other queries: \"none of the Tweeter Apis give the correct count of favorites tested for most of them, all give the… https://t.co/2jnCTMMqV8', '2019-04-07 06:55:19', 5, 2, 0]\n",
            "['Other queries: \"do we have to make two different repositories on Github as \"Python Problem\" and \"CV Problem\". Or we… https://t.co/45x8RhQcAT', '2019-04-07 06:53:38', 4, 1, 0]\n",
            "['Other queries: \"If using Twitter api, it does not include any information about images in the response objects sent… https://t.co/JEWZB2XTPq', '2019-04-07 05:32:27', 6, 1, 0]\n",
            "['Response to some queries asked by students on @midasIIITD task.\\nWhat does the line \"dump the responses into JSONlin… https://t.co/Rr6ri8lyVY', '2019-04-07 05:29:40', 7, 1, 0]\n",
            "['RT @kdnuggets: Top 8 #Free Must-Read #Books on #DeepLearning #KDN https://t.co/1DtlN91Yjj', '2019-04-06 17:11:29', 0, 2, 0]\n",
            "['@nupur_baghel @PennDATS Congratulation @nupur_baghel on getting admit from @PennDATS. \\nShe got 5/10 acceptance. She… https://t.co/ooD8yneUwS', '2019-04-06 16:43:27', 18, 3, 0]\n",
            "['We have emailed the task details to all candidates who have applied to @midasIIITD internship through IIITD portal.… https://t.co/gZwyr7D2Sw', '2019-04-05 16:08:37', 11, 1, 0]\n",
            "['RT @rfpvjr: Our NAACL paper on polarization in language on Twitter surrounding mass shootings is up on arXiv! https://t.co/g7wiegXxDg\\nThis…', '2019-04-05 04:05:11', 0, 16, 0]\n",
            "['RT @kdnuggets: Effective Transfer Learning For NLP https://t.co/Z1m0AzlfVv https://t.co/ccX4Uhxjn8', '2019-04-05 04:04:43', 0, 11, 0]\n",
            "['RT @stanfordnlp: What’s new in @Stanford CS224N Natural Language Processing with Deep Learning for 2019? Question answering—1D CNNs—subword…', '2019-04-03 18:31:53', 0, 59, 0]\n",
            "[\"RT @DeepMindAI: Today we're releasing a large-scale extendable dataset of mathematical questions, for training (and evaluating the abilitie…\", '2019-04-03 17:04:32', 0, 870, 0]\n",
            "                                                 text                 time  \\\n",
            "0   RT @DeepMindAI: Today we're releasing a large-...  2019-04-03 17:04:32   \n",
            "1   RT @stanfordnlp: What’s new in @Stanford CS224...  2019-04-03 18:31:53   \n",
            "2   RT @kdnuggets: Effective Transfer Learning For...  2019-04-05 04:04:43   \n",
            "3   RT @rfpvjr: Our NAACL paper on polarization in...  2019-04-05 04:05:11   \n",
            "4   We have emailed the task details to all candid...  2019-04-05 16:08:37   \n",
            "5   @nupur_baghel @PennDATS Congratulation @nupur_...  2019-04-06 16:43:27   \n",
            "6   RT @kdnuggets: Top 8 #Free Must-Read #Books on...  2019-04-06 17:11:29   \n",
            "7   Response to some queries asked by students on ...  2019-04-07 05:29:40   \n",
            "8   Other queries: \"If using Twitter api, it does ...  2019-04-07 05:32:27   \n",
            "9   Other queries: \"do we have to make two differe...  2019-04-07 06:53:38   \n",
            "10  Other queries: \"none of the Tweeter Apis give ...  2019-04-07 06:55:19   \n",
            "11  We request all students whose interview are sc...  2019-04-07 11:43:24   \n",
            "12  @sayangdipto123 Submit as per the guideline ag...  2019-04-07 14:17:09   \n",
            "13  @himanchalchandr Meanwhile, complete CV/NLP ta...  2019-04-07 14:17:29   \n",
            "14  @midasIIITD thanks all students who have appea...  2019-04-08 03:27:42   \n",
            "15  Many Congratulations to @midasIIITD student, S...  2019-04-08 07:08:12   \n",
            "16  RT @multimediaeval: Announcing the 2019 MediaE...  2019-04-08 19:38:09   \n",
            "17  RT @emnlp2019: For anyone interested in submit...  2019-04-09 05:04:11   \n",
            "18  RT @Harvard: Professor Jelani Nelson founded A...  2019-04-09 05:04:27   \n",
            "19  RT @IIITDelhi: We are delighted to share that ...  2019-04-09 16:45:07   \n",
            "\n",
            "   likes retweets images  \n",
            "0      0      870      0  \n",
            "1      0       59      0  \n",
            "2      0       11      0  \n",
            "3      0       16      0  \n",
            "4     11        1      0  \n",
            "5     18        3      0  \n",
            "6      0        2      0  \n",
            "7      7        1      0  \n",
            "8      6        1      0  \n",
            "9      4        1      0  \n",
            "10     5        2      0  \n",
            "11     1        1      0  \n",
            "12     0        0      0  \n",
            "13     0        0      0  \n",
            "14     5        0      0  \n",
            "15    14        2      0  \n",
            "16     0       15      0  \n",
            "17     0       12      0  \n",
            "18     0       35      0  \n",
            "19     0        9      0  \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}